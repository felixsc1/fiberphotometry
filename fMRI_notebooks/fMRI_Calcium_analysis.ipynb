{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI analysis with Calcium regressors\n",
    "\n",
    "modified: july 16\n",
    "\n",
    "How to run this:\n",
    "1. First run the *CalciumAnalysis* script on the .lvm file simultaneously acquired with this EPI.\n",
    "2. Copy the EPI scan in AFNI&ast; format and the *regressor_married.1D* files into the same folder.\n",
    "3. Within Linux, run this script on a terminal within the scan folder. (Requires AFNI installation, therefore doesn't work on Windows).\n",
    "\n",
    "All outputs will be in an /analysis subfolder.\n",
    "\n",
    "&ast; To convert Bruker 2dseq to AFNI BRIK format, run the other python script *convert_bruker_batch_nomove.py* in the original main folder of the animal. It will convert each scan and create BRIK files in the same folders as the 2dseq\n",
    "\n",
    "TODO: Currently no ROI signal extraction. Create a ROI mask on the template brain to be used with this script in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import subprocess\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Stimulus onset file needs to be present in some folder (or times can be entered below directly). AFNI requirement: All in one line, with onset times in seconds separated by space. NOT considering the initial cutoff.\n",
    "\n",
    "The *baseline* and *_time* times for the average plots should be same as for previous CalciumAnalysis to allow easily plotting BOLD & Calcium in one figure.\n",
    "\n",
    "TODO: Some of these parameters should be read from the CalciumAnalysis, instead of typing them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_duration = 8 #in seconds\n",
    "TR = 1 #in seconds, e.g. 1.5 for multishot\n",
    "initial_cutoff = 10 #number of volumes to remove (in absence of dummy scans).\n",
    "\n",
    "blurFWHM = 0.3 # In [mm]. Rule-of-thumb: 1.5x the voxel resolution.\n",
    "highpass = 210 # period [s]. Any signal slower than this will be removed. Should be at least 2x inter-stim. interval\n",
    "\n",
    "# Stimulus File\n",
    "\n",
    "#stimulus_times = '/media/sf_linuxscripts/stim_files/singleblock.1D' \n",
    "#stimulus_times = '/media/sf_linuxscripts/stim_files/suwon_short_8sON_52sOFF.1D'\n",
    "\n",
    "# alternatively enter the times directly here:\n",
    "# stimulus_times = \"'1D: 180 270 360 450 540 630 720 810 1000 1090 1180 1270 1360 1450 1540 1630'\"  #important to have double quotes on both sides like: \"'1D: 60 120'\"\n",
    "\n",
    "\n",
    "# For averaging of blocks:\n",
    "\n",
    "baseline = 10 # baseline to consider before each block\n",
    "_time = 60 # how many seconds to display after stim block ends\n",
    "\n",
    "# Location of the EPI template for coregistration (should be a representative animal with same geometry settings)\n",
    "template_path = '/media/sf_MRIDATA/Template7T/TEMPLATE+orig'\n",
    "\n",
    "roi_path = '/media/sf_MRIDATA/Template7T/ROIS+orig'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1D: 120 210 300 390 480 570 660 750 840 930 1020 1110 1200 1290 1380'\n"
     ]
    }
   ],
   "source": [
    "# Alternatively create new stimulus series with starttime (baseline), Number of blocks, and inter-stimulus interval (ISI)\n",
    "starttime = 120\n",
    "Nblocks = 15\n",
    "ISI = 90\n",
    "\n",
    "stimList=list(range(starttime,starttime+Nblocks*ISI,ISI))\n",
    "stimString=' '.join(map(str,stimList))\n",
    "stimulus_times = \"'1D: \"+stimString+\"'\"\n",
    "print(stimulus_times)\n",
    "# stimulus_times = \"'1D: 120 210 300 390 480  '\"  #important to have double quotes on both sides like: \"'1D: 60 120'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /media/sf_MRIDATA/Test/newAnalysis/E8+orig.BRIK\n"
     ]
    }
   ],
   "source": [
    "if 'file_path' not in vars():\n",
    "    root = Tk()\n",
    "    ftypes = [('EPI Scan',\"*.BRIK*\"),(\"All Files\",\"*.*\")]\n",
    "    ttl = \"Select file\"\n",
    "    dir1 = '/media/sf_MRIDATA'\n",
    "\n",
    "    root.withdraw()\n",
    "    file_path = askopenfilename(filetypes = ftypes, initialdir = dir1, title = ttl)\n",
    "    root.update()\n",
    "    root.destroy()\n",
    "\n",
    "    print('loaded '+file_path)\n",
    "\n",
    "scanname=os.path.splitext(os.path.basename(file_path))[0][:-5]\n",
    "data_path = os.path.dirname(file_path)  \n",
    "os.chdir(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read scan & regressor files\n",
    "Create a new subfolder /analysis and copy everything in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcium_files = \"*regressor*.1D\"\n",
    "# cwd = os.getcwd()\n",
    "# calcium_regressors = glob.glob(os.path.join(cwd,calcium_files))\n",
    "calcium_regressors = glob.glob(os.path.join(data_path,calcium_files))\n",
    "\n",
    "newfolder = os.path.join(data_path,'analyzed')\n",
    "os.mkdir(newfolder)\n",
    "for i in calcium_regressors:\n",
    "    shutil.copy(i,newfolder)\n",
    "\n",
    "# file1 = scanname+'+orig.BRIK'\n",
    "# file2= scanname+'+orig.HEAD'\n",
    "# copy_file1 = os.path.join(file1)\n",
    "# copy_file2 = os.path.join(file2)\n",
    "# shutil.copy(copy_file1,newfolder)\n",
    "# shutil.copy(copy_file2,newfolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFNI Coregistration & Preprocessing\n",
    "Currently only coregisters the EPI to another template EPI. But allows to create group maps and consistent/easier ROI drawing.\n",
    "In the future an atlas could be coregistered to the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAFNI(inputstring):\n",
    "    print(inputstring)\n",
    "    subprocess.run(inputstring,shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dTcat -prefix /media/sf_MRIDATA/Test/newAnalysis/analysis/E8 E8+orig'[10..$]'\n",
      "3dTcat -prefix /media/sf_MRIDATA/Test/newAnalysis/analysis/single_timepoint E8+orig'[0]'\n",
      "python2.7 /home/virtualfelix/abin/align_epi_anat.py -dset2to1 -dset1 /media/sf_MRIDATA/Template7T/TEMPLATE+orig -dset2 single_timepoint+orig -child_dset2 E8+orig  -dset1_strip None -dset2_strip None -overwrite -big_move -volreg on -volreg_method 3dvolreg -volreg_opts '-Fourier -zpad 1' -Allineate_opts '-maxrot 10 -maxshf 3 -conv 0.005 -twofirst -twoblur 0.8 -source_automask+2 -final wsinc5' -tshift on -tshift_opts '-tzero 0 -quintic' -dset2_base 0 -volreg_base 0 -suffix .volreg -cost ls\n",
      "3dTstat -prefix rm.mean E8.volreg+orig\n",
      "3dcalc -a E8.volreg+orig -b rm.mean+orig -expr 'min(200, a/b*100)*step(a)*step(b)' -prefix rE8.scale\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dTcat -prefix '+ newfolder + '/' + scanname + ' ' + scanname + \"+orig'[\"+ str(initial_cutoff) + \"..$]'\")\n",
    "runAFNI('3dTcat -prefix '+ newfolder + '/single_timepoint' + ' ' + scanname + \"+orig'[0]'\")\n",
    "\n",
    "os.chdir(newfolder)\n",
    "\n",
    "runAFNI(\"python2.7 /home/virtualfelix/abin/align_epi_anat.py -dset2to1 -dset1 \" + template_path + \" -dset2 single_timepoint+orig\" \\\n",
    "                                \" -child_dset2 \" + scanname + '+orig ' \\\n",
    "                                \" -dset1_strip None -dset2_strip None\"  \\\n",
    "                                \" -overwrite\" \\\n",
    "                                \" -big_move\" \\\n",
    "                                \" -volreg on -volreg_method 3dvolreg\" \\\n",
    "                                \" -volreg_opts '-Fourier -zpad 1'\" \\\n",
    "                                \" -Allineate_opts '-maxrot 10 -maxshf 3 -conv 0.005 -twofirst -twoblur 0.8 -source_automask+2 -final wsinc5'\" \\\n",
    "                                \" -tshift on -tshift_opts '-tzero 0 -quintic'\" \\\n",
    "                                \" -dset2_base 0\" \\\n",
    "                                \" -volreg_base 0\" \\\n",
    "                                \" -suffix .volreg\" \\\n",
    "                                \" -cost ls\")\n",
    "    \n",
    "runAFNI('3dTstat -prefix rm.mean' + ' ' + scanname + '.volreg+orig')\n",
    "runAFNI('3dcalc -a ' + scanname + '.volreg+orig -b rm.mean+orig'\\\n",
    "                    \" -expr 'min(200, a/b*100)*step(a)*step(b)' -prefix r\" + scanname + '.scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dTproject -input r*.scale+orig.BRIK.Z -passband 0.004761904761904762 99999 -blur 0.3 -prefix CleanedData\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dTproject -input r*.scale+orig.BRIK.Z -passband ' + str(1/highpass) + ' 99999 -blur ' + str(blurFWHM) + ' -prefix CleanedData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM analyses\n",
    "For now just uses the SPM basis set (SPMG3) as HRF for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Just using the **stimulus timing** as regressor (no calcium information).\n",
    "\n",
    "Output in *statsSPM_el+orig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dDeconvolve -input CleanedData+orig -polort 0 -nodmbase -overwrite -num_stimts 1 -stim_times 1 '1D: 120 210 300 390 480 570 660 750 840 930 1020 1110 1200 1290 1380 1470 1560 1650 1740' 'SPMG3(8)' -stim_times_subtract 10 -stim_label 1 electro -iresp 1 HRF_SPM_el -fout -tout -x1D XSPM.xmat.1D -xjpeg XSPM.jpg -fitts fittsSPM_el -errts errtsSPM_el -bucket statsSPM_el -cbucket regcoeffsSPM_el\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dDeconvolve -input CleanedData+orig' \\\n",
    "                    ' -polort 0' \\\n",
    "                    ' -nodmbase' \\\n",
    "                    ' -overwrite' \\\n",
    "                    ' -num_stimts 1' \\\n",
    "                    ' -stim_times 1 ' +  stimulus_times + \\\n",
    "                    \" 'SPMG3(\" + str(stim_duration) + \")'\" \\\n",
    "                    ' -stim_times_subtract ' + str(initial_cutoff*TR) + \\\n",
    "                    ' -stim_label 1 electro' \\\n",
    "                    ' -iresp 1 HRF_SPM_el' \\\n",
    "                    ' -fout -tout -x1D XSPM.xmat.1D -xjpeg XSPM.jpg' \\\n",
    "                    ' -fitts fittsSPM_el' \\\n",
    "                    ' -errts errtsSPM_el' \\\n",
    "                    ' -bucket statsSPM_el' \\\n",
    "                    ' -cbucket regcoeffsSPM_el')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Just using the **first calcium channel** as regressor.\n",
    "\n",
    "Output is *stats_Neuron+orig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dDeconvolve -input CleanedData+orig -polort 0 -nodmbase -overwrite -num_stimts 1 -stim_times_AM1 1 /media/sf_MRIDATA/Test/newAnalysis/regressor1_married.1D 'SPMG3(8)' -stim_label 1 Neuro -iresp 1 HRF_SPM_Neuron -fout -tout -fitts fitts_Neuron -bucket stats_Neuron -cbucket regcoeffs_Neuron\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dDeconvolve -input CleanedData+orig' \\\n",
    "                    ' -polort 0' \\\n",
    "                    ' -nodmbase' \\\n",
    "                    ' -overwrite'\t \\\n",
    "                    ' -num_stimts 1' \\\n",
    "                    ' -stim_times_AM1 1 ' +  calcium_regressors[0] + \\\n",
    "                    \" 'SPMG3(\" + str(stim_duration) + \")'\" \\\n",
    "#                    ' -stim_times_subtract ' + str(initial_cutoff*TR) + \\\n",
    "                    ' -stim_label 1 Neuro' \\\n",
    "                    ' -iresp 1 HRF_SPM_Neuron' \\\n",
    "                    ' -fout -tout' \\\n",
    "                    ' -fitts fitts_Neuron' \\\n",
    "                    ' -bucket stats_Neuron' \\\n",
    "                    ' -cbucket regcoeffs_Neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Just using the **second calcium channel** as regressor.\n",
    "\n",
    "Output is *stats_Astro+orig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dDeconvolve -input CleanedData+orig -polort 0 -nodmbase -overwrite -num_stimts 1 -stim_times_AM1 1 /media/sf_MRIDATA/Test/newAnalysis/regressor2_married.1D 'SPMG3(8)' -stim_label 1 Astro -iresp 1 HRF_SPM_Astro -fout -tout -fitts fitts_Astro -bucket stats_Astro -cbucket regcoeffs_Astro\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dDeconvolve -input CleanedData+orig' \\\n",
    "                    ' -polort 0' \\\n",
    "                    ' -nodmbase' \\\n",
    "                    ' -overwrite'\t \\\n",
    "                    ' -num_stimts 1' \\\n",
    "                    ' -stim_times_AM1 1 ' + calcium_regressors[1] + \\\n",
    "                    \" 'SPMG3(\" + str(stim_duration) + \")'\" \\\n",
    "#                    ' -stim_times_subtract ' + str(initial_cutoff*TR) + \\\n",
    "                    ' -stim_label 1 Astro' \\\n",
    "                    ' -iresp 1 HRF_SPM_Astro' \\\n",
    "                    ' -fout -tout' \\\n",
    "                    ' -fitts fitts_Astro' \\\n",
    "                    ' -bucket stats_Astro' \\\n",
    "                    ' -cbucket regcoeffs_Astro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using **both calcium channels** as regressors.\n",
    "\n",
    "Output is *stats_BothCh+orig*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3dDeconvolve -input CleanedData+orig -polort 0 -nodmbase -overwrite -num_stimts 2 -stim_times_AM1 1 /media/sf_MRIDATA/Test/newAnalysis/regressor1_married.1D 'SPMG3(8)' -stim_times_AM1 2 /media/sf_MRIDATA/Test/newAnalysis/regressor2_married.1D 'SPMG3(8)' -num_glt 2 -stim_label 1 Neuro -stim_label 2 Astro -glt_label 1 NeuroMinusAstro  -glt_label 2 AstroMinusNEuro  -gltsym 'SYM: +Neuro -Astro' -gltsym 'SYM: +Astro -Neuro' -fout -tout -fitts fitts_BothCh -bucket stats_BothCh\n"
     ]
    }
   ],
   "source": [
    "runAFNI('3dDeconvolve -input CleanedData+orig' \\\n",
    "                    ' -polort 0' \\\n",
    "                    ' -nodmbase' \\\n",
    "                    ' -overwrite' \\\n",
    "                    ' -num_stimts 2' \\\n",
    "                    ' -stim_times_AM1 1 ' + calcium_regressors[0] + \\\n",
    "                    \" 'SPMG3(\" + str(stim_duration) + \")'\" \\\n",
    "                    ' -stim_times_AM1 2 ' + calcium_regressors[1] + \\\n",
    "                    \" 'SPMG3(\" + str(stim_duration) + \")'\" \\\n",
    "#                    ' -stim_times_subtract ' + str(initial_cutoff*TR) + \\\n",
    "                    ' -num_glt 2' \\\n",
    "                    ' -stim_label 1 Neuro' \\\n",
    "                    ' -stim_label 2 Astro' \\\n",
    "                    ' -glt_label 1 NeuroMinusAstro ' \\\n",
    "                    ' -glt_label 2 AstroMinusNEuro ' \\\n",
    "                    \" -gltsym 'SYM: +Neuro -Astro'\" \\\n",
    "                    \" -gltsym 'SYM: +Astro -Neuro'\" \\\n",
    "                    ' -fout -tout' \\\n",
    "                    ' -fitts fitts_BothCh' \\\n",
    "                    ' -bucket stats_BothCh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4a. Probably unnecessary:  Both calcium channels as regressors but in reverse order.  (To check if order of regressors affects statistics)\n",
    "\n",
    "Output is *stats_BothCh_reversed+orig*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging all stimulus blocks\n",
    "\n",
    "Creates the file:\n",
    "- average_raw+orig   with the actual BOLD timecourse averaged across all blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "for i in stimList:\n",
    "    runAFNI('3dTcat -prefix temp_average_raw' + str(k) + ' CleanedData+orig[' + str(int(i) - initial_cutoff - baseline ) + '..' + str(int(i) + stim_duration + _time) +']')\n",
    "    k += 1\n",
    "\n",
    "# runAFNI('3dTcat -prefix average_spm' + str(stim_times_all_loaded[0]) + ' fittsSPM_el+orig[' + str(stim_times_all_loaded[0] - baseline ) + '..' + str(stim_times_all_loaded[0] + stim_duration + _time) +']')\n",
    "\n",
    "runAFNI('3dMean -prefix average_raw temp_average_raw*')\n",
    "\n",
    "runAFNI(\"bash -c 'rm -f temp_average* &>/dev/null'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runAFNI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bbb5e944cbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunAFNI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3dROIstats -mask '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mroi_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' CleanedData+orig > ROIdata.1D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'runAFNI' is not defined"
     ]
    }
   ],
   "source": [
    "runAFNI('3dROIstats -mask ' + roi_path + ' CleanedData+orig > ROIdata.1D')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
